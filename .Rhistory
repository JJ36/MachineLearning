content2 = content(html2,as="text")
html2 = GET(url,line=2)
content2 = content(html2,as="text")
html2 = GET(url,line=100)
help(content)
parsedHtml = htmlParse(content2)#,asText=TRUE)
parsedHtml
class(parsedHtml)
parsedHtml[1]
help(HTMLInternalDocument)
??HTMLInternalDocument
textHtml = readlines(content2)
textHtml = readline(content2)
textHtml
textHtml = readline(content2)
textHtml = readLines(content2)
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 = GET(url,line=100)
close(url)
content2 = content(html2,as="text")
# content2
#parsedHtml = htmlParse(content2)#,asText=TRUE)
#parsedHtml
textHtml = readLines(content2)
textHtml
url <- "http://biostat.jhsph.edu/~jleek/contact.html"
html2 = GET(url,line=100)
content2 = content(html2,as="text")
close(url)
textHtml = readLines(content2)
help(readLines)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con) # you can set the number of line to read
close(con)
class(html)
class(htmlCode)
con = url("http://biostat.jhsph.edu/~jleek/contact.html",n=100)
htmlCode = readLines(con) # you can set the number of line to read
close(con)
class(htmlCode)
htmlCode[1:100]
htmlCode[10]
nbchar(htmlCode[10]))
nbchar(htmlCode[10])
nchar(htmlCode[10])
nchar(htmlCode[10,20,30,100])
nchar(htmlCode[c(10,20,30,100)])
library("rhdf5")
con = file("C:\Users\Jean-Jacques\Google Drive\DOCUMENTS\BIG DATA\R\getdata-wksst8110.for")
help(url)
help(url)
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
data = H5read(con)
close(con)
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
data = h5read(con)
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
data = readLines(con)
close(con)
data[2]
data[1]
data
as.data.frame(data)
head(as.data.frame(data))
as.data.frame(data)[1]
help(readLines)
help(cat)
library("rhdf5")
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
cat(file=con,sep=" ")
data = readLines(con)
close(con)
unlink("test1")
as.data.frame(data)[1]
data
library("rhdf5")
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
cat(file=con,sep=" ")
data = readLines(con)
close(con)
data
library("rhdf5")
con = file("C:/Users/Jean-Jacques/Google Drive/DOCUMENTS/BIG DATA/R/getdata-wksst8110.for")
data = readLines(con,sep=" ")
```
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
library(caret)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~ .,method="rpart",data=training) # rpart classification by tree
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages(rattle)
install.packages('rattle')
library(rattle)
fancyRpartPlot(modFit$finalModel)
## Example: Iris Data
data(iris); library(ggplot2)
library(caret)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
## Run the tree calssification
modFit <- train(Species ~ .,method="rpart",data=training) # rpart classification by tree
print(modFit$finalModel)
## Plot the tree
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
## Prettier plots
#install.packages('rattle')
library(rattle)
fancyRpartPlot(modFit$finalModel)
library(rpart)
fancyRpartPlot(modFit$finalModel)
library(rpart.plot)
install.packages('rpart.plot')
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
install.packages('ElemStatLearn')
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
ll <- matrix(NA,nrow=10,ncol=155)
for(i in 1:10){
ss <- sample(1:dim(ozone)[1],replace=T)
ozone0 <- ozone[ss,]; ozone0 <- ozone0[order(ozone0$ozone),]
loess0 <- loess(temperature ~ ozone,data=ozone0,span=0.2)
ll[i,] <- predict(loess0,newdata=data.frame(ozone=1:155))
}
plot(ozone$ozone,ozone$temperature,pch=19,cex=0.5)
for(i in 1:10){lines(1:155,ll[i,],col="grey",lwd=2)}
lines(1:155,apply(ll,2,mean),col="red",lwd=2)
summary(ozone)
dim(ozone)
ctreeBag$fit
data(iris); library(ggplot2)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
library(caret)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit
getTree(modFit$finalModel,k=2)
irisP <- classCenter(training[,c(3,4)], training$Species, modFit$finalModel$prox)
irisP <- as.data.frame(irisP); irisP$Species <- rownames(irisP)
p <- qplot(Petal.Width, Petal.Length, col=Species,data=training)
p + geom_point(aes(x=Petal.Width,y=Petal.Length,col=Species),size=5,shape=4,data=irisP)
pred <- predict(modFit,testing); testing$predRight <- pred==testing$Species
table(pred,testing$Species)
## Wage example
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
## Fit the model
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
print(modFit)
qplot(predict(modFit,testing),wage,data=testing)
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=iris$Case,p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
head(iris)
names(iris)
names(segmentationOriginal)
head(segmentationOriginal)
Setseed(124)
Set.seed(125)
set.seed(125)
fit <- train(Case ~ .,data=training,method="rpart")
names(segmentationOriginal)
names(training)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training); dim(testing)
head(segmentationOriginal)
names(segmentationOriginal)
set.seed(125)
fit <- train(Case ~ .,data=training,method="rpart")
pred <- predict(fit,newdata=testing)
pred
training[Case]
training[1:10,"Case"]
TotalIntench2 = 23,000; FiberWidthCh1 = 10; PerimStatusCh1=2
TotalIntench2 = 23000; FiberWidthCh1 = 10; PerimStatusCh1=2
pred
fit
names(training)
x
x <- data.frame()
x$TotalIntench2 <- 23000
x$FiberWidthCh1 <- 10
x$PerimStatusCh1 <- 2
x
x <- data.frame( TotalIntench2 = 23000; FiberWidthCh1 = 10; PerimStatusCh1=2 )
predict(fit,newdata=x)
names(x)
names(x) <- names(testing)
modFit$finalModel
set.seed(125)
fit <- train(Case ~ .,data=training,method="rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training); dim(testing)
head(segmentationOriginal)
names(segmentationOriginal)
set.seed(125)
fit <- train(Case ~ .,data=training,method="rpart")
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
library(rattle)
fit <- train(Case ~ .,data=training,method="rpart")
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
library(rattle)
summary(segmentationOriginal$Case)
inTrain <- grep("Train",segmentationOriginal$Case)
inTrain <- createDataPartition(y=segmentationOriginal$Case,, list=FALSE)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(rattle)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training); dim(testing)
head(segmentationOriginal)
names(segmentationOriginal)
set.seed(125)
fit <- train(Case ~ .,data=training,method="rpart")
modFit$finalModel
plot(modFit$finalModel, uniform = TRUE, main = "Classification Tree")
text(modFit$finalModel, use.n = TRUE, all = TRUE, cex = .8)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
predict(modFit, newdata = train)
library(rattle)
summary(segmentationOriginal$Case)
inTrain <- grep("Train",segmentationOriginal$Case)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Class~.,data=training,method="rpart")
fancyRpartPlot(fit$finalModel)
predData <- training[1:3,]
which(colnames(training)=="TotalIntenCh2")
which(colnames(training)=="FiberWidthCh1")
which(colnames(training)=="PerimStatusCh1")
predData[1,c(103,50,85)]=c(23000,10,2)
predData[2,c(103,50,85)]=c(50000,10,100)
predData[3,c(103,50,85)]=c(57000,8,100)
predict(fit,predData)
fit <- train(Class~.,data=training,method="gbm")
fancyRpartPlot(fit$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages(spgmm)
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
fit <- train(area~.,data=olive,method="rpart")
names(olive)
fit <- train(Area~.,data=olive,method="rpart")
predict(fit,newdata)
newdata = as.data.frame(t(colMeans(olive)))
predict(fit,newdata)
head(olive)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
names(SAheart)
fit <- train(sdb~.,data=SAheart,method="glm",family="binomial")
fit <- train(sbp~.,data=SAheart,method="glm",family="binomial")
summary(trainSA)
fit <- train(sbp~c(age,alcohol,obesity,tobacco,typea,ldl),data=SAheart,method="glm",family="binomial")
fit <- train(sbp~list(age,alcohol,obesity,tobacco,typea,ldl),data=SAheart,method="glm",family="binomial")
fit <- train(sbp~age+alcohol+obesity+tobacco+typea+ldl),data=SAheart,method="glm",family="binomial")
fit <- train(sbp~age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,method="glm",family="binomial")
fit <- train(sbp~age+alcohol+obesity+tobacco+typea+ldl,data=SAheart,method="glm",famhist="binomial")
fit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(fit,trainSA))
missClass(testSA$chd,predict(fit,testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
names(vowel)
names(vowel.train)
y<-as.factor(vowel.train$y)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
fit <- train(y~.,data=vowel.train,method="rf")
help(varImp)
fit
varImp(fit)
train <- read.csv("./pml-training.csv")
test <- read.csv("./pml-testing.csv")
dim(train)
names(train)
summary(train[8:159])
setwd("~/R/assignmentMachLearn")
train <- read.csv("./pml-training.csv")
test <- read.csv("./pml-testing.csv")
dim(train)
names(train)
summary(train[8:159])
train[kurtosis_picth_dumbbell]
train$kurtosis_picth_dumbbell
help(is.null)
is.null(train$kurtosis_picth_dumbbell)
is.null(train$kurtosis_picth_dumbbell[1])
is.null(train$kurtosis_picth_dumbbell[2])
NonPred <- names[train[1:7]]
NonPred <- names[train][1:7]
NonPred <- names(train[1:7])
NonPred
lapply(train,x,function(x) sum(is.na(x))/length(x))
lapply(train,2,function(x) sum(is.na(x))/length(x))
apply(train,2,function(x) sum(is.na(x))/length(x))
NAprop <- apply(train,2,function(x) sum(is.na(x))/length(x))
NAprop[NAprop<0.97]
NAprop <- apply(train[-NonPred],2,function(x) sum(is.na(x))/length(x))
NonPred <- names(train[1:7])
NAprop <- apply(train[-NonPred],2,function(x) sum(is.na(x))/length(x))
names(train[-NonPred])
NonPred
NAprop <- apply(train[,-NonPred],2,function(x) sum(is.na(x))/length(x))
names(train[,-NonPred])
names(train[,-1])
names(train[,-"X"])
names(train[,-c("X")])
nzv <- nearZeroVar(train)
library(caret)
nzv <- nearZeroVar(train)
class(nzv)
nzv
grep("X|user_name|cvtd_timestamp", names(train))
help(grep)
grep(names(train[1:7]),names(train))
names(train[1:7]) %in% names(train)
NAprop <- apply(train[,-NonPred],2,function(x) sum(is.na(x))/length(x))
NonPred <- [1:7]
[1:5]
NonPred <- 1:7
NAprop <- which(apply(train[,-NonPred],2,function(x) sum(is.na(x))/length(x))>0.97)
NAprop
hellp(which)
help(which)
class(NAprop)
NonPred <- c(NonPred,NAprop)
help(nearZeroVar)
nzv(train)
Nonvar <- nzv(train[,-c(NonPred)])
NonPred <- c(NonPred,160)
names(train[,-NonPred])
summary((train[,-NonPred]))
NAfeat <- which(apply(train[,-NonPred],2,function(x) sum(is.na(x))/length(x))>0.97)
NonPred <- c(NonPred,NAfeat)
NonVar <- nzv(train[,-c(NonPred)])
NonPred <- c(NonPred,NonVar)
NonPred <- c(NonPred,160)
summary((train[,-NonPred]))
NAfeat <- which(apply(train,2,function(x) sum(is.na(x))/length(x))>0.97)
NonPred <- c(NonPred,NAfeat)
NonVar <- nzv(train)
NonPred <- c(NonPred,NonVar)
NonPred <- c(NonPred,160)
summary((train[,-NonPred]))
names((train[,-NonPred]))
NonPred
train0 <- train[,-NonPred]
train0 <- train[,-160]
NonPred <- 1:7
train0 <- train[,-NonPred]
NAfeat <- which(apply(train0,2,function(x) sum(is.na(x))/length(x))>0.97)
train0 <- train0[,-NAfeat]
NonVar <- nzv(train0)
train0 <- train0[,-NonVar]
names(train0)
train0 <- train[,-160]
NonPred <- 1:7
train0 <- train0[,-NonPred]
NAfeat <- which(apply(train0,2,function(x) sum(is.na(x))/length(x))>0.97)
train0 <- train0[,-NAfeat]
NonVar <- nzv(train0)
train0 <- train0[,-NonVar]
names(train0)
help(nzv)
library(caret)
test0 <- test[,-160][,-NonPred][,-NAfeat][,-NonVar]
names(test0)
library(caret)
train <- read.csv("./pml-training.csv")
test <- read.csv("./pml-testing.csv")
dim(train)
names(train)
train0 <- train
NonPred <- 1:7
train0 <- train0[,-NonPred]
summary(train0)
NAfeat <- which(apply(train0,2,function(x) sum(is.na(x))/length(x))>0.97)
train0 <- train0[,-NAfeat] # extracting features with more than 97% of NA values
NonVar <- nzv(train0)
train0 <- train0[,-NonVar] # extracting features with to few variability
CrossVal0 <- test[,-NonPred][,-NAfeat][,-NonVar] # same thing on test set
names(train0) # list of predictors
set.seed(1321321)
inTrain <- createDataPartition(y = train0$classe, p = 0.7, list = FALSE)
training <- train0[inTrain,]
testing <- train0[-intrain,]
testing <- train0[-inTrain,]
set.seed(6546454562)
set.seed(6464)
fitClassTree <- fit(classe~.,data=training,method="rpart")
fitClassTree <- train(classe~.,data=training,method="rpart")
fitRandFor <- train(classe~.,data=training,method="rf")
confClassTree <- confusionMatrix(TestClassTree,testing$classe)
TestClassTree <- predict(fitClassTree,newdata=testing)
confClassTree <- confusionMatrix(TestClassTree,testing$classe)
confClassTree
TestLDA<- predict(fitLDA,newdata=testing)
fitLDA  <- train(classe~.,data=training,method="lda")
fitBoost <- train(classe~.,data=training,method="gbm")
confLDA <- confusionMatrix(TestLDA,testing$classe)$table
TestClassTree <- predict(fitClassTree,newdata=testing)
TestLDA<- predict(fitLDA,newdata=testing)
confClassTree <- confusionMatrix(TestClassTree,testing$classe)$table
confClassTree
confLDA <- confusionMatrix(TestLDA,testing$classe)$table
confLDA
confClassTree <- confusionMatrix(TestClassTree,testing$classe)
confClassTree
confClassTree <- confusionMatrix(TestClassTree,testing$classe)$Accuracy
confClassTree
confClassTree <- confusionMatrix(TestClassTree,testing$classe)
names(confClassTree)
names(confClassTree$overall)
(confClassTree$overall)$Accuracy
(confClassTree$overall)
(confClassTree$overall$Accuracy)
(confClassTree$overall[Accuracy])
ov <- confClassTree$overall
ov$Accuracy
ov
ov[1]
confClassTree$overall[1]
confLDA <- confusionMatrix(TestLDA,testing$classe)$table
confLDA$overall[1]
confLDA <- confusionMatrix(TestLDA,testing$classe)
confLDA$overall[1]
help(train)
fitClassTree <- train(classe~.,data=training,method="rpart",trace=TRUE)
